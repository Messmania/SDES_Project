Algo:
===Training====
1. Prepare a list with tweets and their sentiments(as tuples)--More the known sentiment-tweets btr the training--pos_tweets and neg_tweets
2. Separate the distinct words from all the training tweets---get_words()--output is all_words which is a list
3. Sort them according to their frequency--get_word_features()--output is word_features --this is global list which is our stored data for matching against new input
4. Func extract_features takes a input tweet and matches with every word in word_features list and returns a dict of type {word:True or False} for 
    each word in word_features list
    --output is feature set dict called say TweetXi which contains {"contains word0":True,"contains word1":False...so on} for every tweet i.e. i= 0 to 9
5. Now this extraction must be done on many tweets, so(just for example?) we give our list of (words,sentiments) from our training set of pos n neg tweets only
6. This is done using nltk.classify.apply_features(extract_features,tweets)
    -this calls extract_features for each value in tweets --output:training_set
    this contains, [(TweetX0,sentiment),(TweetX1,s),(TweetX3,s),...,(TweetX10,s)]
7. Now this training_set is given to NB Classifier method to generate a NBclassifier (Read more about it)-- output is classifier
8. This classifier has method classify which generates the sentiment of the passed tweet.


==Sentiment analysis=========
1. method findSentiment uses the classifier to get the sentiment as classifier.classify(feature-set-dict(input))
